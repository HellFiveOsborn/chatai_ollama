# ChatAI Ollama
================

![Example](assets/my-logo.svg)

A simple chat interface for Ollama AI model, designed to be used on mobile devices.

## Features

* User-friendly interface for interacting with Ollama AI model
* Supports multiple models and configurations
* Real-time response generation
* Configurable settings for temperature, top-k, and top-p
* Local storage of chat history and settings

## Getting Started

1. Clone the repository and open the `index.html` file in your browser.
2. Select a model from the dropdown list and enter a prompt in the input field.
3. Click the "Generate" button to receive a response from the Ollama AI model.
4. Configure settings by clicking the "Config" button and adjusting the sliders and input fields.

## Configuration

The configuration settings are stored locally in the browser's storage. You can adjust the following settings:

* System prompt: the initial prompt given to the Ollama AI model
* Temperature: controls the creativity of the response
* Top-k: controls the diversity of the response
* Top-p: controls the focus of the response

## Development

This project uses the following technologies:

* HTML, Tailwindcss, and JavaScript for the frontend
* Ollama AI model for response generation
* LocalStorage for storing chat history and settings

## Contributing

Contributions are welcome! If you'd like to contribute to this project, please fork the repository and submit a pull request.

## License

This project is licensed under the MIT License.